# Plan 01 : Parser PDF m√©dicaux

**Version** : 1.0.0  
**Date** : 20 novembre 2025  
**Statut** : ‚úÖ Impl√©ment√©

---

## Vue d'ensemble

Import intelligent des donn√©es depuis Andaman 7, MaSant√© et autres sources.

---

## üéØ **OBJECTIF**

Permettre √† votre m√®re d'importer facilement tous ses documents m√©dicaux depuis les apps qu'elle utilise d√©j√† (Andaman 7, MaSant√©, R√©seau Sant√© Wallon) pour avoir **tout au m√™me endroit** dans CIA.

---

## üìã **BESOINS IDENTIFI√âS**

### **Besoin Principal**
- ‚úÖ Importer documents depuis Andaman 7 (export PDF)
- ‚úÖ Importer documents depuis MaSant√© (export PDF)
- ‚úÖ Importer depuis R√©seau Sant√© Wallon (export PDF)
- ‚úÖ Parsing automatique pour extraire m√©tadonn√©es
- ‚úÖ Interface simple : drag & drop ou s√©lection fichier

### **Fonctionnalit√©s Requises**
- üì• Import manuel PDF (drag & drop)
- üîç Extraction automatique m√©tadonn√©es (m√©decin, date, type examen)
- üìã D√©tection type document (ordonnance, r√©sultat, compte-rendu)
- üè∑Ô∏è Classification automatique par cat√©gorie
- üîó Association automatique avec m√©decins existants
- ‚úÖ Validation et pr√©visualisation avant import

---

## üèóÔ∏è **ARCHITECTURE**

### **Stack Technique**

```
Frontend (Flutter)
‚îú‚îÄ‚îÄ file_picker (s√©lection fichiers)
‚îú‚îÄ‚îÄ pdfx ou syncfusion_flutter_pdf (lecture PDF)
‚îî‚îÄ‚îÄ drag_and_drop (interface drag & drop)

Backend (Python FastAPI)
‚îú‚îÄ‚îÄ PyPDF2 / pdfplumber (extraction texte)
‚îú‚îÄ‚îÄ Tesseract OCR (PDF scann√©s)
‚îú‚îÄ‚îÄ spaCy / NLTK (NLP sant√©)
‚îî‚îÄ‚îÄ regex (extraction m√©tadonn√©es)
```

### **Structure Fichiers**

```
arkalia_cia/
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ screens/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ import_documents_screen.dart      # Interface import
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_parser_service.dart           # Service parsing PDF
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ document_import_service.dart      # Service import documents
‚îÇ   ‚îî‚îÄ‚îÄ widgets/
‚îÇ       ‚îú‚îÄ‚îÄ pdf_preview_widget.dart           # Pr√©visualisation PDF
‚îÇ       ‚îî‚îÄ‚îÄ import_progress_widget.dart        # Barre progression
‚îî‚îÄ‚îÄ arkalia_cia_python_backend/
    ‚îú‚îÄ‚îÄ pdf_parser/
    ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
    ‚îÇ   ‚îú‚îÄ‚îÄ pdf_extractor.py                 # Extraction texte PDF
    ‚îÇ   ‚îú‚îÄ‚îÄ ocr_processor.py                 # OCR pour PDF scann√©s
    ‚îÇ   ‚îú‚îÄ‚îÄ metadata_extractor.py            # Extraction m√©tadonn√©es
    ‚îÇ   ‚îî‚îÄ‚îÄ document_classifier.py           # Classification documents
    ‚îî‚îÄ‚îÄ api/
        ‚îî‚îÄ‚îÄ import_api.py                    # API import documents
```

---

## üîß **IMPL√âMENTATION D√âTAILL√âE**

### **√âtape 1 : Backend - Extraction Texte PDF**

**Fichier** : `arkalia_cia_python_backend/pdf_parser/pdf_extractor.py`

```python
"""
Extraction texte depuis PDF m√©dicaux
Inspiration : EDS-NLP (APHP) pour techniques extraction
"""
import pdfplumber
import PyPDF2
from typing import Optional, Dict, List
import logging

logger = logging.getLogger(__name__)


class PDFExtractor:
    """Extracteur texte depuis PDF m√©dicaux"""
    
    def __init__(self):
        self.supported_formats = ['.pdf']
    
    def extract_text(self, pdf_path: str) -> Dict[str, any]:
        """
        Extrait le texte d'un PDF m√©dical
        
        Returns:
            {
                'text': str,           # Texte complet
                'pages': List[str],     # Texte par page
                'metadata': Dict,        # M√©tadonn√©es PDF
                'is_scanned': bool       # Si PDF scann√© (n√©cessite OCR)
            }
        """
        try:
            # Essayer avec pdfplumber (meilleur pour PDF texte)
            with pdfplumber.open(pdf_path) as pdf:
                text_pages = []
                full_text = ""
                
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text_pages.append(page_text)
                        full_text += page_text + "\n"
                
                # Si pas de texte, c'est probablement scann√©
                is_scanned = len(full_text.strip()) < 100
                
                return {
                    'text': full_text,
                    'pages': text_pages,
                    'metadata': pdf.metadata,
                    'is_scanned': is_scanned,
                    'page_count': len(pdf.pages)
                }
        
        except Exception as e:
            logger.error(f"Erreur extraction PDF: {e}")
            # Fallback sur PyPDF2
            return self._extract_with_pypdf2(pdf_path)
    
    def _extract_with_pypdf2(self, pdf_path: str) -> Dict[str, any]:
        """Fallback avec PyPDF2"""
        try:
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text_pages = []
                full_text = ""
                
                for page in pdf_reader.pages:
                    page_text = page.extract_text()
                    text_pages.append(page_text)
                    full_text += page_text + "\n"
                
                return {
                    'text': full_text,
                    'pages': text_pages,
                    'metadata': pdf_reader.metadata,
                    'is_scanned': len(full_text.strip()) < 100,
                    'page_count': len(pdf_reader.pages)
                }
        except Exception as e:
            logger.error(f"Erreur PyPDF2: {e}")
            raise
```

---

### **√âtape 2 : Backend - OCR pour PDF Scann√©s**

**Fichier** : `arkalia_cia_python_backend/pdf_parser/ocr_processor.py`

```python
"""
OCR pour PDF scann√©s (Tesseract)
"""
import pytesseract
from pdf2image import convert_from_path
from typing import Dict, List
import logging
import tempfile
import os

logger = logging.getLogger(__name__)


class OCRProcessor:
    """Processeur OCR pour PDF scann√©s"""
    
    def __init__(self):
        # Configuration Tesseract pour fran√ßais
        self.tesseract_config = '--oem 3 --psm 6 -l fra+eng'
    
    def process_scanned_pdf(self, pdf_path: str) -> Dict[str, any]:
        """
        Traite un PDF scann√© avec OCR
        
        Returns:
            {
                'text': str,
                'pages': List[str],
                'confidence': float,  # Confiance moyenne OCR
                'is_scanned': True
            }
        """
        try:
            # Convertir PDF en images
            images = convert_from_path(pdf_path, dpi=300)
            
            text_pages = []
            total_confidence = 0.0
            
            for i, image in enumerate(images):
                # OCR sur chaque page
                ocr_data = pytesseract.image_to_data(
                    image,
                    config=self.tesseract_config,
                    output_type=pytesseract.Output.DICT
                )
                
                # Extraire texte et confiance
                page_text = ""
                page_confidences = []
                
                for j, word in enumerate(ocr_data['text']):
                    if word.strip():
                        page_text += word + " "
                        conf = float(ocr_data['conf'][j])
                        if conf > 0:
                            page_confidences.append(conf)
                
                text_pages.append(page_text.strip())
                
                if page_confidences:
                    avg_conf = sum(page_confidences) / len(page_confidences)
                    total_confidence += avg_conf
            
            avg_confidence = total_confidence / len(images) if images else 0.0
            
            return {
                'text': "\n\n".join(text_pages),
                'pages': text_pages,
                'confidence': avg_confidence,
                'is_scanned': True,
                'page_count': len(images)
            }
        
        except Exception as e:
            logger.error(f"Erreur OCR: {e}")
            raise
```

---

### **√âtape 3 : Backend - Extraction M√©tadonn√©es**

**Fichier** : `arkalia_cia_python_backend/pdf_parser/metadata_extractor.py`

```python
"""
Extraction m√©tadonn√©es depuis texte PDF m√©dical
Inspiration : EDS-NLP pour extraction entit√©s nomm√©es sant√©
"""
import re
from datetime import datetime
from typing import Dict, Optional, List
import logging

logger = logging.getLogger(__name__)


class MetadataExtractor:
    """Extracteur m√©tadonn√©es documents m√©dicaux"""
    
    def __init__(self):
        # Patterns pour d√©tection dates (format belge)
        self.date_patterns = [
            r'\d{1,2}[/-]\d{1,2}[/-]\d{2,4}',  # 15/11/2025 ou 15-11-2025
            r'\d{1,2}\s+\w+\s+\d{4}',           # 15 novembre 2025
            r'\d{4}[/-]\d{1,2}[/-]\d{1,2}',     # 2025-11-15
        ]
        
        # Patterns pour d√©tection m√©decins
        self.doctor_patterns = [
            r'Dr\.?\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)',  # Dr. Dupont
            r'Docteur\s+([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)',  # Docteur Martin
            r'([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*),\s*Dr\.?',  # Dupont, Dr.
        ]
        
        # Patterns pour d√©tection types examens
        self.exam_patterns = {
            'radio': r'(?:radio|radiographie|RX|X-ray)',
            'analyse': r'(?:analyse|pr√©l√®vement|sang|urine)',
            'scanner': r'(?:scanner|CT|tomodensitom√©trie)',
            'irm': r'(?:IRM|imagerie par r√©sonance)',
            'echographie': r'(?:√©chographie|√©chographie|ultrasons)',
            'biopsie': r'(?:biopsie|pr√©l√®vement)',
        }
    
    def extract_metadata(self, text: str) -> Dict[str, any]:
        """
        Extrait m√©tadonn√©es depuis texte PDF
        
        Returns:
            {
                'date': Optional[datetime],
                'doctor_name': Optional[str],
                'doctor_specialty': Optional[str],
                'exam_type': Optional[str],
                'document_type': str,  # 'ordonnance', 'resultat', 'compte_rendu'
                'keywords': List[str]
            }
        """
        metadata = {
            'date': self._extract_date(text),
            'doctor_name': self._extract_doctor_name(text),
            'doctor_specialty': self._extract_specialty(text),
            'exam_type': self._extract_exam_type(text),
            'document_type': self._classify_document_type(text),
            'keywords': self._extract_keywords(text)
        }
        
        return metadata
    
    def _extract_date(self, text: str) -> Optional[datetime]:
        """Extrait la date du document"""
        for pattern in self.date_patterns:
            matches = re.findall(pattern, text)
            if matches:
                try:
                    # Essayer de parser la date
                    date_str = matches[0]
                    # Normaliser format
                    if '/' in date_str:
                        parts = date_str.split('/')
                        if len(parts) == 3:
                            day, month, year = parts
                            if len(year) == 2:
                                year = '20' + year
                            return datetime(int(year), int(month), int(day))
                except:
                    continue
        return None
    
    def _extract_doctor_name(self, text: str) -> Optional[str]:
        """Extrait le nom du m√©decin"""
        for pattern in self.doctor_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                return matches[0].strip()
        return None
    
    def _extract_specialty(self, text: str) -> Optional[str]:
        """Extrait la sp√©cialit√© du m√©decin"""
        specialties = [
            'cardiologue', 'dermatologue', 'gyn√©cologue', 'ophtalmologue',
            'orthop√©diste', 'pneumologue', 'rhumatologue', 'neurologue',
            'g√©n√©raliste', 'm√©decin g√©n√©ral'
        ]
        
        text_lower = text.lower()
        for specialty in specialties:
            if specialty in text_lower:
                return specialty.capitalize()
        return None
    
    def _extract_exam_type(self, text: str) -> Optional[str]:
        """Extrait le type d'examen"""
        text_lower = text.lower()
        for exam_type, pattern in self.exam_patterns.items():
            if re.search(pattern, text_lower, re.IGNORECASE):
                return exam_type
        return None
    
    def _classify_document_type(self, text: str) -> str:
        """Classifie le type de document"""
        text_lower = text.lower()
        
        # Mots-cl√©s pour classification
        if any(word in text_lower for word in ['ordonnance', 'prescription', 'm√©dicament']):
            return 'ordonnance'
        elif any(word in text_lower for word in ['r√©sultat', 'analyse', 'laboratoire']):
            return 'resultat'
        elif any(word in text_lower for word in ['compte-rendu', 'rapport', 'consultation']):
            return 'compte_rendu'
        else:
            return 'autre'
    
    def _extract_keywords(self, text: str) -> List[str]:
        """Extrait mots-cl√©s importants"""
        # Mots-cl√©s m√©dicaux communs
        medical_keywords = [
            'diagnostic', 'traitement', 'sympt√¥me', 'pathologie',
            'm√©dicament', 'posologie', 'dosage', 'effet secondaire'
        ]
        
        found_keywords = []
        text_lower = text.lower()
        for keyword in medical_keywords:
            if keyword in text_lower:
                found_keywords.append(keyword)
        
        return found_keywords
```

---

### **√âtape 4 : Backend - Classification Documents**

**Fichier** : `arkalia_cia_python_backend/pdf_parser/document_classifier.py`

```python
"""
Classification intelligente des documents m√©dicaux
Utilise NLP pour classification pr√©cise
"""
from typing import Dict
import logging

logger = logging.getLogger(__name__)


class DocumentClassifier:
    """Classificateur de documents m√©dicaux"""
    
    def classify(self, text: str, metadata: Dict) -> Dict[str, any]:
        """
        Classifie le document avec score de confiance
        
        Returns:
            {
                'category': str,        # 'consultation', 'examen', 'ordonnance', etc.
                'confidence': float,     # 0.0 √† 1.0
                'tags': List[str]       # Tags suppl√©mentaires
            }
        """
        # Classification bas√©e sur m√©tadonn√©es et texte
        doc_type = metadata.get('document_type', 'autre')
        
        # Mapping document_type ‚Üí category
        category_mapping = {
            'ordonnance': 'ordonnance',
            'resultat': 'examen',
            'compte_rendu': 'consultation',
            'autre': 'document_general'
        }
        
        category = category_mapping.get(doc_type, 'document_general')
        
        # Calculer confiance bas√©e sur m√©tadonn√©es compl√®tes
        confidence = self._calculate_confidence(metadata)
        
        # G√©n√©rer tags
        tags = self._generate_tags(metadata, text)
        
        return {
            'category': category,
            'confidence': confidence,
            'tags': tags
        }
    
    def _calculate_confidence(self, metadata: Dict) -> float:
        """Calcule score de confiance"""
        score = 0.0
        
        if metadata.get('date'):
            score += 0.3
        if metadata.get('doctor_name'):
            score += 0.3
        if metadata.get('exam_type'):
            score += 0.2
        if len(metadata.get('keywords', [])) > 0:
            score += 0.2
        
        return min(score, 1.0)
    
    def _generate_tags(self, metadata: Dict, text: str) -> List[str]:
        """G√©n√®re tags pour le document"""
        tags = []
        
        if metadata.get('exam_type'):
            tags.append(metadata['exam_type'])
        
        if metadata.get('doctor_specialty'):
            tags.append(metadata['doctor_specialty'])
        
        # Ajouter tags depuis keywords
        tags.extend(metadata.get('keywords', [])[:3])  # Max 3 keywords
        
        return tags
```

---

### **√âtape 5 : Backend - API Import**

**Fichier** : `arkalia_cia_python_backend/api/import_api.py`

```python
"""
API pour import documents m√©dicaux
"""
from fastapi import APIRouter, UploadFile, File, HTTPException
from typing import List
import tempfile
import os
from ..pdf_parser.pdf_extractor import PDFExtractor
from ..pdf_parser.ocr_processor import OCRProcessor
from ..pdf_parser.metadata_extractor import MetadataExtractor
from ..pdf_parser.document_classifier import DocumentClassifier
import logging

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/import", tags=["import"])

extractor = PDFExtractor()
ocr_processor = OCRProcessor()
metadata_extractor = MetadataExtractor()
classifier = DocumentClassifier()


@router.post("/pdf")
async def import_pdf(file: UploadFile = File(...)):
    """
    Import un PDF m√©dical
    
    Returns:
        {
            'success': bool,
            'document_id': Optional[str],
            'metadata': Dict,
            'preview': str,  # Premi√®res lignes texte
            'requires_review': bool  # Si m√©tadonn√©es incompl√®tes
        }
    """
    try:
        # Sauvegarder fichier temporaire
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_path = tmp_file.name
        
        try:
            # Extraire texte
            extraction_result = extractor.extract_text(tmp_path)
            
            # Si PDF scann√©, utiliser OCR
            if extraction_result['is_scanned']:
                logger.info("PDF scann√© d√©tect√©, utilisation OCR")
                ocr_result = ocr_processor.process_scanned_pdf(tmp_path)
                text = ocr_result['text']
            else:
                text = extraction_result['text']
            
            # Extraire m√©tadonn√©es
            metadata = metadata_extractor.extract_metadata(text)
            
            # Classifier document
            classification = classifier.classify(text, metadata)
            
            # Pr√©visualisation (premi√®res 500 caract√®res)
            preview = text[:500] + "..." if len(text) > 500 else text
            
            # D√©terminer si r√©vision n√©cessaire
            requires_review = metadata.get('confidence', 0.0) < 0.7
            
            return {
                'success': True,
                'metadata': {
                    **metadata,
                    **classification
                },
                'preview': preview,
                'requires_review': requires_review,
                'page_count': extraction_result.get('page_count', 0)
            }
        
        finally:
            # Nettoyer fichier temporaire
            if os.path.exists(tmp_path):
                os.unlink(tmp_path)
    
    except Exception as e:
        logger.error(f"Erreur import PDF: {e}")
        raise HTTPException(status_code=500, detail=str(e))
```

---

### **√âtape 6 : Frontend - Interface Import**

**Fichier** : `arkalia_cia/lib/screens/import_documents_screen.dart`

```dart
import 'package:flutter/material.dart';
import 'package:file_picker/file_picker.dart';
import 'package:dio/dio.dart';
import '../services/document_import_service.dart';
import '../widgets/pdf_preview_widget.dart';
import '../widgets/import_progress_widget.dart';

class ImportDocumentsScreen extends StatefulWidget {
  @override
  _ImportDocumentsScreenState createState() => _ImportDocumentsScreenState();
}

class _ImportDocumentsScreenState extends State<ImportDocumentsScreen> {
  final DocumentImportService _importService = DocumentImportService();
  bool _isImporting = false;
  double _progress = 0.0;
  String? _previewText;
  Map<String, dynamic>? _metadata;

  Future<void> _pickAndImportPDF() async {
    try {
      FilePickerResult? result = await FilePicker.platform.pickFiles(
        type: FileType.custom,
        allowedExtensions: ['pdf'],
      );

      if (result != null) {
        setState(() {
          _isImporting = true;
          _progress = 0.0;
        });

        // Import via service
        final importResult = await _importService.importPDF(
          result.files.single.path!,
          onProgress: (progress) {
            setState(() {
              _progress = progress;
            });
          },
        );

        setState(() {
          _isImporting = false;
          _previewText = importResult['preview'];
          _metadata = importResult['metadata'];
        });

        // Afficher r√©sultat
        _showImportResult(importResult);
      }
    } catch (e) {
      setState(() {
        _isImporting = false;
      });
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(content: Text('Erreur import: $e')),
      );
    }
  }

  void _showImportResult(Map<String, dynamic> result) {
    showDialog(
      context: context,
      builder: (context) => AlertDialog(
        title: Text('Import r√©ussi'),
        content: Column(
          mainAxisSize: MainAxisSize.min,
          crossAxisAlignment: CrossAxisAlignment.start,
          children: [
            if (result['metadata'] != null) ...[
              Text('M√©decin: ${result['metadata']['doctor_name'] ?? 'Non d√©tect√©'}'),
              Text('Date: ${result['metadata']['date'] ?? 'Non d√©tect√©e'}'),
              Text('Type: ${result['metadata']['document_type'] ?? 'Non d√©tect√©'}'),
            ],
            SizedBox(height: 16),
            ElevatedButton(
              onPressed: () {
                // Sauvegarder document
                Navigator.pop(context);
              },
              child: Text('Sauvegarder'),
            ),
          ],
        ),
      ),
    );
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: Text('Importer Documents'),
      ),
      body: Padding(
        padding: EdgeInsets.all(16.0),
        child: Column(
          children: [
            // Zone drag & drop
            Expanded(
              child: _buildDropZone(),
            ),
            
            // Bouton s√©lection fichier
            ElevatedButton.icon(
              onPressed: _isImporting ? null : _pickAndImportPDF,
              icon: Icon(Icons.upload_file),
              label: Text('S√©lectionner PDF'),
            ),
            
            // Barre progression
            if (_isImporting)
              ImportProgressWidget(progress: _progress),
            
            // Pr√©visualisation
            if (_previewText != null)
              Expanded(
                child: PdfPreviewWidget(text: _previewText!),
              ),
          ],
        ),
      ),
    );
  }

  Widget _buildDropZone() {
    return DragTarget<String>(
      onWillAccept: (data) => true,
      onAccept: (data) {
        // G√©rer drop fichier
        _pickAndImportPDF();
      },
      builder: (context, candidateData, rejectedData) {
        return Container(
          decoration: BoxDecoration(
            border: Border.all(
              color: candidateData.isNotEmpty ? Colors.blue : Colors.grey,
              width: 2,
            ),
            borderRadius: BorderRadius.circular(8),
          ),
          child: Center(
            child: Column(
              mainAxisAlignment: MainAxisAlignment.center,
              children: [
                Icon(Icons.cloud_upload, size: 64, color: Colors.grey),
                SizedBox(height: 16),
                Text(
                  'Glissez vos PDF ici',
                  style: TextStyle(fontSize: 18),
                ),
                Text('ou cliquez sur le bouton ci-dessous'),
              ],
            ),
          ),
        );
      },
    );
  }
}
```

---

## ‚úÖ **TESTS**

### **Tests Backend**

```python
# tests/test_pdf_extractor.py
def test_extract_text_from_pdf():
    extractor = PDFExtractor()
    result = extractor.extract_text('test_document.pdf')
    assert result['text'] is not None
    assert len(result['pages']) > 0

def test_detect_scanned_pdf():
    extractor = PDFExtractor()
    result = extractor.extract_text('scanned_document.pdf')
    assert result['is_scanned'] == True

# tests/test_metadata_extractor.py
def test_extract_doctor_name():
    extractor = MetadataExtractor()
    text = "Consultation avec Dr. Dupont le 15/11/2025"
    metadata = extractor.extract_metadata(text)
    assert metadata['doctor_name'] == 'Dupont'
    assert metadata['date'] is not None
```

### **Tests Frontend**

```dart
// test/import_documents_test.dart
void main() {
  testWidgets('Import PDF affiche pr√©visualisation', (tester) async {
    await tester.pumpWidget(ImportDocumentsScreen());
    
    // Simuler s√©lection fichier
    await tester.tap(find.text('S√©lectionner PDF'));
    await tester.pumpAndSettle();
    
    // V√©rifier pr√©visualisation affich√©e
    expect(find.byType(PdfPreviewWidget), findsOneWidget);
  });
}
```

---

## üöÄ **PERFORMANCE**

### **Optimisations**

1. **Cache extraction texte** : Ne pas r√©-extraire si d√©j√† fait
2. **OCR asynchrone** : Traiter OCR en arri√®re-plan
3. **Compression images OCR** : R√©duire taille avant OCR
4. **Indexation texte** : Indexer pour recherche rapide

### **Limites**

- **Taille max PDF** : 50 MB
- **Pages max** : 100 pages
- **Timeout OCR** : 60 secondes par page

---

## üîê **S√âCURIT√â**

1. **Validation fichiers** : V√©rifier extension et type MIME
2. **Scan antivirus** : Scanner fichiers upload√©s
3. **Limite taille** : Emp√™cher upload fichiers trop gros
4. **Isolation** : Traiter fichiers dans environnement isol√©
5. **Nettoyage** : Supprimer fichiers temporaires apr√®s traitement

---

## üìÖ **TIMELINE**

### **Semaine 1 : Backend Extraction**
- [ ] Jour 1-2 : PDFExtractor (extraction texte)
- [ ] Jour 3-4 : OCRProcessor (OCR PDF scann√©s)
- [ ] Jour 5 : Tests extraction

### **Semaine 2 : Backend M√©tadonn√©es**
- [ ] Jour 1-2 : MetadataExtractor (extraction m√©tadonn√©es)
- [ ] Jour 3 : DocumentClassifier (classification)
- [ ] Jour 4-5 : Tests m√©tadonn√©es

### **Semaine 3 : API & Frontend**
- [ ] Jour 1-2 : API import (import_api.py)
- [ ] Jour 3-4 : Interface Flutter (import_documents_screen.dart)
- [ ] Jour 5 : Tests int√©gration

### **Semaine 4 : Finalisation**
- [ ] Jour 1-2 : Optimisations performance
- [ ] Jour 3 : Tests finaux
- [ ] Jour 4-5 : Documentation

---

## üìö **RESSOURCES**

- **PyPDF2** : https://pypdf2.readthedocs.io/
- **pdfplumber** : https://github.com/jsvine/pdfplumber
- **Tesseract OCR** : https://github.com/tesseract-ocr/tesseract
- **spaCy** : https://spacy.io/
- **EDS-NLP (Inspiration)** : https://www.aphp.fr/actualites/ia-en-sante-lentrepot-de-donnees-de-sante-de-lap-hp-confirme-sa-demarche-open-source

---

**Statut** : üìã **PLAN VALID√â**  
**Priorit√©** : üî¥ **CRITIQUE**  
**Temps estim√©** : 3-4 semaines

